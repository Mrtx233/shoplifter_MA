#### url_ Unlimited _ ManualEnd_SingleUrl.py——url_无限标签\_手动end键\_单url

```
pip install requests lxml pandas colorama openpyxl selenium
```

### 代码逻辑说明

1. **导入模块**: 导入所需的标准库和第三方库，用于各种功能，如HTTP请求、HTML解析、数据处理、文件操作、日志记录、浏览器自动化等。

2. **设置日志记录**: 配置日志记录器，以便在控制台上显示信息和错误。

3. **设置请求头**: 定义一个`headers`字典，以模拟浏览器访问目标网站。

4. **函数`write_to_excel`**:

   - 逻辑

     :

     - 检查文件是否存在。
     - 如果文件不存在，创建一个新的Excel文件并写入数据。
     - 如果文件存在，加载现有文件并检查工作表是否存在。
     - 如果工作表存在，读取现有数据并与新数据合并。
     - 将合并后的数据写入工作表。

5. **函数`extract_links`**:

   - 逻辑

     :

     - 启动浏览器并访问指定的URL。
     - 使用XPath定位元素并提取链接。
     - 返回提取的链接列表。
     - 确保浏览器在完成后关闭。

6. **主程序逻辑**:

   - 定义要爬取的URL和XPath。
   - 调用`extract_links`函数提取目标页面的链接。
   - 定义文件和路径相关变量。
   - 创建存储目录（如果不存在）。
   - 定义一个空的DataFrame用于存储数据。
   - 遍历提取的链接，逐个处理页面内容。
   - 提取页面的标题、目录、发布时间、来源等信息，并保存为.docx文件。
   - 检查文件大小，如果为0KB则删除文件，否则记录文件信息。
   - 将数据写入Excel文件。
